{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhaaskarthik/impressionism-image-generator/blob/main/post_impressionism_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJkkc9KrCcjz",
        "outputId": "1cdfc391-849f-46b5-c997-11148c308b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: jax 0.4.23\n",
            "Uninstalling jax-0.4.23:\n",
            "  Successfully uninstalled jax-0.4.23\n",
            "Found existing installation: jaxlib 0.4.23+cuda12.cudnn89\n",
            "Uninstalling jaxlib-0.4.23+cuda12.cudnn89:\n",
            "  Successfully uninstalled jaxlib-0.4.23+cuda12.cudnn89\n",
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Collecting jax[cuda11_cudnn805]==0.3.10\n",
            "  Downloading jax-0.3.10.tar.gz (939 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.23.5)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.11.4)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (4.5.0)\n",
            "Collecting jaxlib==0.3.10+cuda11.cudnn805 (from jax[cuda11_cudnn805]==0.3.10)\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.10%2Bcuda11.cudnn805-cp310-none-manylinux2014_x86_64.whl (175.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.7/175.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers<3.0,>=1.12 (from jaxlib==0.3.10+cuda11.cudnn805->jax[cuda11_cudnn805]==0.3.10)\n",
            "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.3.10-py3-none-any.whl size=1088046 sha256=e0eb4ca304f9dc248177c697c7f5922e49fe15157b4ab09df18329b07aa1a0ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/b8/74/0e87ee9c40aa5187c299d70fc5b0ceffcbb124175b8873eaed\n",
            "Successfully built jax\n",
            "Installing collected packages: flatbuffers, jaxlib, jax\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.5.26\n",
            "    Uninstalling flatbuffers-23.5.26:\n",
            "      Successfully uninstalled flatbuffers-23.5.26\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.10 which is incompatible.\n",
            "flax 0.8.0 requires jax>=0.4.19, but you have jax 0.3.10 which is incompatible.\n",
            "orbax-checkpoint 0.4.4 requires jax>=0.4.9, but you have jax 0.3.10 which is incompatible.\n",
            "tensorflow 2.15.0 requires flatbuffers>=23.5.26, but you have flatbuffers 2.0.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flatbuffers-2.0.7 jax-0.3.10 jaxlib-0.3.10+cuda11.cudnn805\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.8.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.8.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCloning into 'stylegan2-ada-pytorch'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 131 (delta 0), reused 1 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (131/131), 1.13 MiB | 3.19 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall jax jaxlib -y\n",
        "!pip install \"jax[cuda11_cudnn805]==0.3.10\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "!pip install torch==1.8.1 torchvision==0.9.1\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVcueG5bCz2V",
        "outputId": "1ce1183d-0b82-4fff-f161-ad1a8f11f386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 5355/5355 [12:33<00:00,  7.11it/s]\n"
          ]
        }
      ],
      "source": [
        "CMD = \"python stylegan2-ada-pytorch/dataset_tool.py \"\\\n",
        "  \"--source drive/MyDrive/gan_paintings/images \"\\\n",
        "  \"--dest drive/MyDrive/gan_paintings/dataset\"\n",
        "\n",
        "!{CMD}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9rGMoLHLNRV"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "IMAGE_PATH = 'drive/MyDrive/gan_paintings/images'\n",
        "files = [f for f in listdir(IMAGE_PATH) if isfile(join(IMAGE_PATH, f))]\n",
        "\n",
        "base_size = None\n",
        "for file in tqdm(files):\n",
        "  file2 = os.path.join(IMAGE_PATH,file)\n",
        "  img = Image.open(file2)\n",
        "  sz = img.size\n",
        "  if base_size and sz!=base_size:\n",
        "    print(f\"Inconsistant size: {file2}\")\n",
        "  elif img.mode!='RGB':\n",
        "    print(f\"Inconsistant color format: {file2}\")\n",
        "  else:\n",
        "    base_size = sz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "Uf5hlbKWI6mw",
        "outputId": "48637a08-b23c-4d67-de3c-a7b9ef052682"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-615c2da4fb48>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/usr/bin/python3 stylegan2-ada-pytorch/train.py \"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;34mf\"--snap {SNAP} --outdir {EXPERIMENTS} --data {DATA}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{cmd}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;31m# TODO(b/115527726): Rather than sleep, poll for incoming messages from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;31m# the frontend in the same poll as for the output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Modify these to suit your needs\n",
        "EXPERIMENTS = \"drive/MyDrive/gan_paintings/experiments\"\n",
        "DATA = \"drive/MyDrive/gan_paintings/dataset\"\n",
        "SNAP = 25\n",
        "\n",
        "# Build the command and run it\n",
        "cmd = f\"/usr/bin/python3 stylegan2-ada-pytorch/train.py \"\\\n",
        "  f\"--snap {SNAP} --outdir {EXPERIMENTS} --data {DATA}\"\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8kvOXG3Z1Lr",
        "outputId": "ff0fe889-32d5-40cd-b7d1-5d5171a70711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 4,\n",
            "  \"network_snapshot_ticks\": 4,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"drive/MyDrive/gan_paintings/dataset\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 5355,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 1024\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 32768,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.002,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.002,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 52.4288\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 4,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"ema_kimg\": 1.25,\n",
            "  \"ema_rampup\": null,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"drive/MyDrive/gan_paintings/experiments/00045-dataset-auto1-resumecustom/network-snapshot-000016.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"drive/MyDrive/gan_paintings/experiments/00046-dataset-auto1-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   drive/MyDrive/gan_paintings/experiments/00046-dataset-auto1-resumecustom\n",
            "Training data:      drive/MyDrive/gan_paintings/dataset\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   5355\n",
            "Image resolution:   1024\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  5355\n",
            "Image shape: [3, 1024, 1024]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"drive/MyDrive/gan_paintings/experiments/00045-dataset-auto1-resumecustom/network-snapshot-000016.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator              Parameters  Buffers  Output shape         Datatype\n",
            "---                    ---         ---      ---                  ---     \n",
            "mapping.fc0            262656      -        [4, 512]             float32 \n",
            "mapping.fc1            262656      -        [4, 512]             float32 \n",
            "mapping                -           512      [4, 18, 512]         float32 \n",
            "synthesis.b4.conv1     2622465     32       [4, 512, 4, 4]       float32 \n",
            "synthesis.b4.torgb     264195      -        [4, 3, 4, 4]         float32 \n",
            "synthesis.b4:0         8192        16       [4, 512, 4, 4]       float32 \n",
            "synthesis.b4:1         -           -        [4, 512, 4, 4]       float32 \n",
            "synthesis.b8.conv0     2622465     80       [4, 512, 8, 8]       float32 \n",
            "synthesis.b8.conv1     2622465     80       [4, 512, 8, 8]       float32 \n",
            "synthesis.b8.torgb     264195      -        [4, 3, 8, 8]         float32 \n",
            "synthesis.b8:0         -           16       [4, 512, 8, 8]       float32 \n",
            "synthesis.b8:1         -           -        [4, 512, 8, 8]       float32 \n",
            "synthesis.b16.conv0    2622465     272      [4, 512, 16, 16]     float32 \n",
            "synthesis.b16.conv1    2622465     272      [4, 512, 16, 16]     float32 \n",
            "synthesis.b16.torgb    264195      -        [4, 3, 16, 16]       float32 \n",
            "synthesis.b16:0        -           16       [4, 512, 16, 16]     float32 \n",
            "synthesis.b16:1        -           -        [4, 512, 16, 16]     float32 \n",
            "synthesis.b32.conv0    2622465     1040     [4, 512, 32, 32]     float32 \n",
            "synthesis.b32.conv1    2622465     1040     [4, 512, 32, 32]     float32 \n",
            "synthesis.b32.torgb    264195      -        [4, 3, 32, 32]       float32 \n",
            "synthesis.b32:0        -           16       [4, 512, 32, 32]     float32 \n",
            "synthesis.b32:1        -           -        [4, 512, 32, 32]     float32 \n",
            "synthesis.b64.conv0    2622465     4112     [4, 512, 64, 64]     float32 \n",
            "synthesis.b64.conv1    2622465     4112     [4, 512, 64, 64]     float32 \n",
            "synthesis.b64.torgb    264195      -        [4, 3, 64, 64]       float32 \n",
            "synthesis.b64:0        -           16       [4, 512, 64, 64]     float32 \n",
            "synthesis.b64:1        -           -        [4, 512, 64, 64]     float32 \n",
            "synthesis.b128.conv0   1442561     16400    [4, 256, 128, 128]   float16 \n",
            "synthesis.b128.conv1   721409      16400    [4, 256, 128, 128]   float16 \n",
            "synthesis.b128.torgb   132099      -        [4, 3, 128, 128]     float16 \n",
            "synthesis.b128:0       -           16       [4, 256, 128, 128]   float16 \n",
            "synthesis.b128:1       -           -        [4, 256, 128, 128]   float32 \n",
            "synthesis.b256.conv0   426369      65552    [4, 128, 256, 256]   float16 \n",
            "synthesis.b256.conv1   213249      65552    [4, 128, 256, 256]   float16 \n",
            "synthesis.b256.torgb   66051       -        [4, 3, 256, 256]     float16 \n",
            "synthesis.b256:0       -           16       [4, 128, 256, 256]   float16 \n",
            "synthesis.b256:1       -           -        [4, 128, 256, 256]   float32 \n",
            "synthesis.b512.conv0   139457      262160   [4, 64, 512, 512]    float16 \n",
            "synthesis.b512.conv1   69761       262160   [4, 64, 512, 512]    float16 \n",
            "synthesis.b512.torgb   33027       -        [4, 3, 512, 512]     float16 \n",
            "synthesis.b512:0       -           16       [4, 64, 512, 512]    float16 \n",
            "synthesis.b512:1       -           -        [4, 64, 512, 512]    float32 \n",
            "synthesis.b1024.conv0  51297       1048592  [4, 32, 1024, 1024]  float16 \n",
            "synthesis.b1024.conv1  25665       1048592  [4, 32, 1024, 1024]  float16 \n",
            "synthesis.b1024.torgb  16515       -        [4, 3, 1024, 1024]   float16 \n",
            "synthesis.b1024:0      -           16       [4, 32, 1024, 1024]  float16 \n",
            "synthesis.b1024:1      -           -        [4, 32, 1024, 1024]  float32 \n",
            "---                    ---         ---      ---                  ---     \n",
            "Total                  28794124    2797104  -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b1024.fromrgb  128         16       [4, 32, 1024, 1024]  float16 \n",
            "b1024.skip     2048        16       [4, 64, 512, 512]    float16 \n",
            "b1024.conv0    9248        16       [4, 32, 1024, 1024]  float16 \n",
            "b1024.conv1    18496       16       [4, 64, 512, 512]    float16 \n",
            "b1024          -           16       [4, 64, 512, 512]    float16 \n",
            "b512.skip      8192        16       [4, 128, 256, 256]   float16 \n",
            "b512.conv0     36928       16       [4, 64, 512, 512]    float16 \n",
            "b512.conv1     73856       16       [4, 128, 256, 256]   float16 \n",
            "b512           -           16       [4, 128, 256, 256]   float16 \n",
            "b256.skip      32768       16       [4, 256, 128, 128]   float16 \n",
            "b256.conv0     147584      16       [4, 128, 256, 256]   float16 \n",
            "b256.conv1     295168      16       [4, 256, 128, 128]   float16 \n",
            "b256           -           16       [4, 256, 128, 128]   float16 \n",
            "b128.skip      131072      16       [4, 512, 64, 64]     float16 \n",
            "b128.conv0     590080      16       [4, 256, 128, 128]   float16 \n",
            "b128.conv1     1180160     16       [4, 512, 64, 64]     float16 \n",
            "b128           -           16       [4, 512, 64, 64]     float16 \n",
            "b64.skip       262144      16       [4, 512, 32, 32]     float32 \n",
            "b64.conv0      2359808     16       [4, 512, 64, 64]     float32 \n",
            "b64.conv1      2359808     16       [4, 512, 32, 32]     float32 \n",
            "b64            -           16       [4, 512, 32, 32]     float32 \n",
            "b32.skip       262144      16       [4, 512, 16, 16]     float32 \n",
            "b32.conv0      2359808     16       [4, 512, 32, 32]     float32 \n",
            "b32.conv1      2359808     16       [4, 512, 16, 16]     float32 \n",
            "b32            -           16       [4, 512, 16, 16]     float32 \n",
            "b16.skip       262144      16       [4, 512, 8, 8]       float32 \n",
            "b16.conv0      2359808     16       [4, 512, 16, 16]     float32 \n",
            "b16.conv1      2359808     16       [4, 512, 8, 8]       float32 \n",
            "b16            -           16       [4, 512, 8, 8]       float32 \n",
            "b8.skip        262144      16       [4, 512, 4, 4]       float32 \n",
            "b8.conv0       2359808     16       [4, 512, 8, 8]       float32 \n",
            "b8.conv1       2359808     16       [4, 512, 4, 4]       float32 \n",
            "b8             -           16       [4, 512, 4, 4]       float32 \n",
            "b4.mbstd       -           -        [4, 513, 4, 4]       float32 \n",
            "b4.conv        2364416     16       [4, 512, 4, 4]       float32 \n",
            "b4.fc          4194816     -        [4, 512]             float32 \n",
            "b4.out         513         -        [4, 1]               float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          29012513    544      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "2024-01-31 09:45:25.033479: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-01-31 09:45:25.075378: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-01-31 09:45:25.077737: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-01-31 09:45:57.855383: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-31 09:45:57.855433: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-31 09:45:57.857434: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-31 09:45:59.453192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 3m 13s       sec/tick 81.9    sec/kimg 20486.32 maintenance 111.3  cpumem 2.97   gpumem 13.45  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "{\"results\": {\"fid50k_full\": 29.86377689124657}, \"metric\": \"fid50k_full\", \"total_time\": 3081.561736345291, \"total_time_str\": \"51m 22s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1706697539.8099587}\n",
            "tick 1     kimg 4.0      time 1h 26m 55s   sec/tick 1924.5  sec/kimg 481.13  maintenance 3097.6 cpumem 4.56   gpumem 7.57   augment 0.030\n",
            "tick 2     kimg 8.0      time 1h 59m 04s   sec/tick 1928.7  sec/kimg 482.18  maintenance 0.4    cpumem 4.54   gpumem 7.78   augment 0.057\n",
            "tick 3     kimg 12.0     time 2h 31m 16s   sec/tick 1931.0  sec/kimg 482.76  maintenance 0.4    cpumem 4.52   gpumem 7.77   augment 0.084\n",
            "tick 4     kimg 16.0     time 3h 04m 10s   sec/tick 1973.6  sec/kimg 493.39  maintenance 0.4    cpumem 4.53   gpumem 7.70   augment 0.109\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 28.497774755250283}, \"metric\": \"fid50k_full\", \"total_time\": 2224.9273195266724, \"total_time_str\": \"37m 05s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000016.pkl\", \"timestamp\": 1706707555.422105}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Modify these to suit your needs\n",
        "EXPERIMENTS = \"drive/MyDrive/gan_paintings/experiments\"\n",
        "NETWORK = \"network-snapshot-000016.pkl\"\n",
        "RESUME = os.path.join(EXPERIMENTS, \\\n",
        "                \"00045-dataset-auto1-resumecustom\", NETWORK)\n",
        "DATA = \"drive/MyDrive/gan_paintings/dataset\"\n",
        "SNAP = 4\n",
        "\n",
        "# Build the command and run it\n",
        "cmd = f\"/usr/bin/python3 /content/stylegan2-ada-pytorch/train.py \"\\\n",
        "  f\"--snap {SNAP} --resume {RESUME} --outdir {EXPERIMENTS} --data {DATA}\"\n",
        "!{cmd}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1M08qDYmBI65jWd6tKVmSsDIYKUXFQtYp",
      "authorship_tag": "ABX9TyMrfzBLjgJahHhWd+rWYx8/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}